# Optimizing Loan Default Prediction through Ensemble Modeling

## 🔄 Overview:
This project aims to explore various machine learning algorithms and evaluate their performance in predicting loan default. By utilizing the Loan_train.csv dataset, different models such as KNN, Decision Tree, Support Vector Machine, and Logistic Regression will be trained and compared to determine the best performing model. The project also covers data visualization, pre-processing, feature selection, and normalization techniques to prepare the data for modeling.

![Category and Subcategory](https://img.shields.io/badge/Data%20Analysis%20and%20prediction-Clustering-blue)
![Category and Subcategory](https://img.shields.io/badge/Clustering-Support%20Vector%20Machines-yellow)

## 🖼️ Images of the Project:
<img align="center" alt="jpg" src="https://raw.githubusercontent.com/moreno32/Optimizing-Loan-Default-Prediction-through-Ensemble-Modeling/master/reports/figures/Optimizing-Loan-Default-Prediction-through-Ensemble-Modeling.png" width="800" height="191" /><br>

## 🎊 Motivation:
Accurately predicting loan default is crucial for financial institutions to minimize risk and maximize profits. This project seeks to find the most effective model to predict loan default by leveraging the available loan data.

## 🏁 Learning Objectives:
1)	Gain experience in data visualization and pre-processing techniques
2)	Compare the performance of various machine learning algorithms in classifying loan default
3)	Evaluate the effectiveness of feature selection and normalization in improving model performance

## ⚙️ Technical Aspects:
The project utilizes the following technologies: pandas, matplotlib, numpy, seaborn, scikit-learn, scipy, itertools, pylab. The data source is the Loan_train.csv dataset which contains 346 loan records with information on loan status, customer details, and loan amount.

## 📚 Data Source:
The Loan_train.csv dataset includes details of 346 customers whose loan are already paid off or defaulted. The data will be loaded using the Pandas library and converted to a date time object for further processing.just 5 zombies images for training.

## 🗂️ Project Structure:
The project will consist of the following stages.
1)	Imports
2)	About dataset
3)	Load Data from CSV File
4)	Convert to date time object
5)	Data visualization and pre-processing
6)	Pre-processing: Feature selection/extraction
7)	Convert Categorical features to numerical values
8)	One Hot Encoding
9)	Feature Selection
10)	Normalize Data
11)	Classification
12)	Model Evaluation using Test set
13)	Report

## 👥 Credits:
The project is a self-directed effort to develop skills in machine learning and data analysis.

## 🔗 Links:
**scikit-learn documentation** - https://scikit-learn.org/stable/index.html

**Pandas documentation** - https://pandas.pydata.org/pandas-docs/stable/

**Matplotlib documentation** - https://matplotlib.org/stable/index.htmlhttps://github.com/fizyr/keras-retinanet

**Seaborn documentation** - https://seaborn.pydata.org/

**Link to Repository**: https://github.com/moreno32/Optimizing-Loan-Default-Prediction-through-Ensemble-Modeling.git

## 🙋‍♂️ Contact me:
<a href= mailto:danielmoreno3291@gmail.com> <img align="center" alt="Abhishek's LinkedIN" width="32px" src="https://cdn4.iconfinder.com/data/icons/social-media-logos-6/512/112-gmail_email_mail-512.png" >
<a href="https://www.linkedin.com/in/dmoreno-ai/"> <img align="center" alt="Abhishek's LinkedIN" width="32px" src="https://cdn-icons-png.flaticon.com/512/174/174857.png">
<a href="https://www.youtube.com/@dmoreno-ai"> <img align="center" alt="Abhishek's LinkedIN" width="32px" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/YouTube_social_white_squircle.svg/2048px-YouTube_social_white_squircle.svg.png" /><br>

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/dmoreno_ai)
